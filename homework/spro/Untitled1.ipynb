{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648183a3-4f63-4d7f-a661-614c5354c132",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visdom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvisdom\u001b[39;00m\n\u001b[0;32m     29\u001b[0m vis \u001b[38;5;241m=\u001b[39m visdom\u001b[38;5;241m.\u001b[39mVisdom()\n\u001b[0;32m     31\u001b[0m USE_CUDA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visdom'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "#matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import visdom\n",
    "vis = visdom.Visdom()\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 100\n",
    "batch_size = 50\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 50000\n",
    "epoch = 0\n",
    "plot_every = 20\n",
    "print_every = 100\n",
    "evaluate_every = 1000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def trim(self, min_count=3):\n",
    "        keep = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep.append(k)\n",
    "\n",
    "        print('total', len(self.word2index))\n",
    "        print('keep', len(keep))\n",
    "        print('keep %', len(keep) / len(self.word2index))\n",
    "\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "\n",
    "        for word in keep:\n",
    "            self.index_word(word)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "#     filename = '../data/%s-%s.txt' % (lang1, lang2)\n",
    "    filename = './data/%s-%s.txt' % (lang1, lang2)\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MIN_LENGTH = 5\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i \", \"he  \", \"she \", \"you \", \"they \", \"we \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) <= MAX_LENGTH and len(p[1].split(' ')) <= MAX_LENGTH and         len(p[0].split(' ')) >= MIN_LENGTH and len(p[1].split(' ')) >= MIN_LENGTH # and \\\n",
    "#         p[1].startswith(good_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]\n",
    "\n",
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)\n",
    "input_lang.trim()\n",
    "output_lang.trim()\n",
    "\n",
    "keep_pairs = []\n",
    "\n",
    "for pair in pairs:\n",
    "    keep_input = True\n",
    "    keep_output = True\n",
    "\n",
    "    for word in pair[0].split(' '):\n",
    "        if word not in input_lang.word2index:\n",
    "            keep_input = False\n",
    "            break\n",
    "\n",
    "    for word in pair[1].split(' '):\n",
    "        if word not in output_lang.word2index:\n",
    "            keep_output = False\n",
    "            break\n",
    "\n",
    "    if keep_input and keep_output:\n",
    "        keep_pairs.append(pair)\n",
    "\n",
    "print(len(pairs))\n",
    "print(len(keep_pairs))\n",
    "print(len(keep_pairs) / len(pairs))\n",
    "pairs = keep_pairs\n",
    "\n",
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [0 for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "def random_batch(batch_size=3):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "\n",
    "    # Choose random pairs\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "        input_seqs.append(indexes_from_sentence(input_lang, pair[0]))\n",
    "        target_seqs.append(indexes_from_sentence(output_lang, pair[1]))\n",
    "\n",
    "    # Zip into pairs, sort by length (descending), unzip\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs = zip(*seq_pairs)\n",
    "\n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch x seq) tensors, transpose into (seq x batch)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_var = input_var.cuda()\n",
    "        target_var = target_var.cuda()\n",
    "\n",
    "    return input_var, input_lengths, target_var, target_lengths\n",
    "\n",
    "random_batch()\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output) # unpack (back to padded)\n",
    "        return output, hidden\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(0)\n",
    "        batch_size = encoder_outputs.size(1)\n",
    "#         print('[attn] seq len', seq_len)\n",
    "#         print('[attn] encoder_outputs', encoder_outputs.size()) # S x B x N\n",
    "#         print('[attn] hidden', hidden.size()) # S=1 x B x N\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(batch_size, seq_len)) # B x S\n",
    "#         print('[attn] attn_energies', attn_energies.size())\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(seq_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "#         print('[attn] attn_energies', attn_energies.size())\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy\n",
    "\n",
    "rnn_output = Variable(torch.zeros(1, 2, 10))\n",
    "encoder_outputs = Variable(torch.zeros(3, 2, 10))\n",
    "attn = Attn('concat', 10)\n",
    "attn(rnn_output, encoder_outputs)\n",
    "\n",
    "attn_weights = torch.zeros(2, 1, 3)\n",
    "print('attn_weights', attn_weights.size())\n",
    "encoder_outputs = torch.zeros(3, 2, 10)\n",
    "print('encoder_outputs', encoder_outputs.size())\n",
    "#    B x N x M\n",
    "#  , B x M x P\n",
    "# -> B x N x P\n",
    "context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "context = context.transpose(0, 1)\n",
    "print('context', context.size())\n",
    "\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time (in order to do teacher forcing)\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "#         print('[decoder] input_seq', input_seq.size()) # batch_size x 1\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, hidden_size) # S=1 x B x N\n",
    "#         print('[decoder] word_embedded', embedded.size())\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "#         print('[decoder] last_hidden', last_hidden.size())\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "#         print('[decoder] rnn_output', rnn_output.size())\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "#         print('[decoder] attn_weights', attn_weights.size())\n",
    "#         print('[decoder] encoder_outputs', encoder_outputs.size())\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "#         print('[decoder] context', context.size())\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "#         print('[decoder] rnn_output', rnn_output.size())\n",
    "#         print('[decoder] context', context.size())\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6)\n",
    "#         output = F.log_softmax(self.out(concat_output))\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights\n",
    "\n",
    "\n",
    "# ## Testing the models\n",
    "# \n",
    "# To make sure the encoder and decoder are working (and working together) we'll do a quick test.\n",
    "# \n",
    "# First by creating and padding a batch of sequences:\n",
    "\n",
    "# In[394]:\n",
    "\n",
    "# Input as batch of sequences of word indexes\n",
    "batch_size = 2\n",
    "input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "print('input_batches', input_batches.size())\n",
    "print('target_batches', target_batches.size())\n",
    "\n",
    "\n",
    "# Create models with a small size (in case you need to manually inspect):\n",
    "\n",
    "# In[395]:\n",
    "\n",
    "# Create models\n",
    "hidden_size = 8\n",
    "n_layers = 2\n",
    "encoder_test = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder_test = LuongAttnDecoderRNN('general', hidden_size, output_lang.n_words, n_layers)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    decoder_test.cuda()\n",
    "\n",
    "\n",
    "# Then running the entire batch of input sequences through the encoder to get per-batch encoder outputs:\n",
    "\n",
    "# In[396]:\n",
    "\n",
    "# Test encoder\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n",
    "print('encoder_outputs', encoder_outputs.size()) # max_len x B x hidden_size\n",
    "print('encoder_hidden', encoder_hidden.size()) # n_layers x B x hidden_size\n",
    "\n",
    "\n",
    "# Then starting with a SOS token, run word tokens through the decoder to get each next word token. Instead of doing this with the whole sequence, it is done one at a time, to support using it's own predictions to make the next prediction. This will be one time step at a time, but batched per time step. In order to get this to work for short padded sequences, the batch size is going to get smaller each time.\n",
    "\n",
    "# In[397]:\n",
    "\n",
    "decoder_attns = torch.zeros(batch_size, MAX_LENGTH, MAX_LENGTH)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "max_length = max(target_lengths)\n",
    "all_decoder_outputs = Variable(torch.zeros(max_length, batch_size, decoder_test.output_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_context = decoder_context.cuda()\n",
    "    all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "loss = 0\n",
    "\n",
    "# import masked_cross_entropy\n",
    "import importlib\n",
    "importlib.reload(masked_cross_entropy)\n",
    "\n",
    "# Run through decoder one time step at a time\n",
    "for t in range(max_length - 1):\n",
    "    decoder_input = target_batches[t]\n",
    "    target_batch = target_batches[t + 1]\n",
    "\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(\n",
    "        decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    print('decoder output = %s, decoder_hidden = %s, decoder_attn = %s'% (\n",
    "        decoder_output.size(), decoder_hidden.size(), decoder_attn.size()\n",
    "    ))\n",
    "    all_decoder_outputs[t] = decoder_output\n",
    "\n",
    "# print('all decoder outputs', all_decoder_outputs.size())\n",
    "# print('target batches', target_batches.size())\n",
    "# print('all_decoder_outputs', all_decoder_outputs.transpose(0, 1).contiguous().view(-1, decoder_test.output_size))\n",
    "print('target lengths', target_lengths)\n",
    "loss = masked_cross_entropy.compute_loss(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    target_batches.transpose(0, 1).contiguous(),\n",
    "    target_lengths\n",
    ")\n",
    "# loss = criterion(all_decoder_outputs, target_batches)\n",
    "# print('loss', loss.size())\n",
    "print('loss', loss.data[0])\n",
    "\n",
    "\n",
    "# # Training\n",
    "# \n",
    "# ## Defining a training iteration\n",
    "# \n",
    "# To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
    "# \n",
    "# ### Teacher Forcing vs. Scheduled Sampling\n",
    "# \n",
    "# \"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
    "# \n",
    "# You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
    "# \n",
    "# The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output.\n",
    "\n",
    "# In[398]:\n",
    "\n",
    "[SOS_token] * 5\n",
    "\n",
    "\n",
    "# In[399]:\n",
    "\n",
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token] * batch_size])).transpose(0, 1)\n",
    "#     print('decoder_input', decoder_input.size())\n",
    "    decoder_context = encoder_outputs[-1]\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "    max_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "    # TODO: Get targets working\n",
    "    if True:\n",
    "        # Run through decoder one time step at a time\n",
    "        for t in range(max_length):\n",
    "#             target_batch = target_batches[t]\n",
    "\n",
    "            # Trim down batches of other inputs\n",
    "#             decoder_hidden = decoder_hidden[:, :len(target_batch)]\n",
    "#             encoder_outputs = encoder_outputs[:, :len(target_batch)]\n",
    "\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "#             print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "\n",
    "#             loss += criterion(decoder_output, target_batch)\n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "\n",
    "            decoder_input = target_batches[t]\n",
    "            # TODO decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    # Teacher forcing: Use the ground-truth target as the next input\n",
    "    elif use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    # Without teacher forcing: use network's own prediction as the next input\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "\n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "#     print('all_decoder_outputs', all_decoder_outputs.size())\n",
    "#     print('target_batches', target_batches.size())\n",
    "    loss = masked_cross_entropy.compute_loss(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # seq x batch -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # seq x batch -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradient norm\n",
    "#     ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "#     dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0], ec, dc\n",
    "\n",
    "# ## Running training\n",
    "\n",
    "# Plus helper functions to print time elapsed and estimated time remaining, given the current time and progress.\n",
    "\n",
    "# In[404]:\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n",
    "\n",
    "def evaluate(input_seq, max_length=MAX_LENGTH):\n",
    "    input_lengths = [len(input_seq)]\n",
    "    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    input_batches = Variable(torch.LongTensor(input_seqs)).transpose(0, 1)\n",
    "    if USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        # Next input is chosen word\n",
    "        # THIS MIGHT BE THE LAST PART OF BATCHING (or is it already going?)\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "\n",
    "    output_words, attentions = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    show_attention(pair[0], output_words, attentions)\n",
    "\n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')\n",
    "\n",
    "def show_plot_visdom():\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    attn_win = 'attention (%s)' % hostname\n",
    "    vis.image(torchvision.transforms.ToTensor()(Image.open(buf)), win=attn_win, opts={'title': attn_win})\n",
    "\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    show_plot_visdom()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions)\n",
    "    win = 'evaluted (%s)' % hostname\n",
    "    text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n",
    "    vis.text(text, win=win, opts={'title': win})\n",
    "\n",
    "\n",
    "# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "\n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "\n",
    "    if epoch == 1:\n",
    "        evaluate_randomly()\n",
    "        continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        evaluate_randomly()\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "        # TODO: Running average helper\n",
    "        ecs.append(eca / plot_every)\n",
    "        dcs.append(dca / plot_every)\n",
    "        ecs_win = 'encoder grad (%s)' % hostname\n",
    "        dcs_win = 'decoder grad (%s)' % hostname\n",
    "        vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n",
    "        vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n",
    "        eca = 0\n",
    "        dca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d162594-d0b6-427b-8dfa-67743df53b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
