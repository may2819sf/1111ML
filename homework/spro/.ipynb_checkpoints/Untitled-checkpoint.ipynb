{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462dfc5d-9c11-4c8d-97c7-d632ee747a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4144fcab-ecdb-473e-8ec4-90b990932562",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8251480-2900-4195-9600-0f5bef79ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a14ab2-b186-454c-bde2-a79e37daf1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb466c85-379d-4f76-acab-7ae9dcea3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./data/%s-%s.txt' % (lang1, lang2),errors='ignore').read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87dd1da4-55ed-48ca-936f-fc1147a035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(good_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ef418b-530e-4877-a8ef-1572048a72f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 197463 sentence pairs\n",
      "Trimmed to 0 sentence pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m input_lang, output_lang, pairs \u001b[38;5;241m=\u001b[39m prepare_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfra\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Print an example pair\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\random.py:346\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bfa5e3a-6946-4c01-957c-8052be504e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d860f5e-ae7c-44e8-81e5-f90e82610cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be325b83-fe2c-4171-973e-fc6daeb5fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = GeneralAttn(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45202217-65a9-48a3-ae0e-4fd294a57d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19f6cf82-57a8-4b49-af76-f4c4ca22ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caaf5b34-7d69-4c9e-9002-b4e4784597d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2)\n",
      ")\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     decoder_context \u001b[38;5;241m=\u001b[39m decoder_context\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 24\u001b[0m     decoder_output, decoder_context, decoder_hidden, decoder_attn \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decoder_output\u001b[38;5;241m.\u001b[39msize(), decoder_hidden\u001b[38;5;241m.\u001b[39msize(), decoder_attn\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m     26\u001b[0m     decoder_attns[\u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m decoder_attn\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mAttnDecoderRNN.forward\u001b[1;34m(self, word_input, last_context, last_hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     29\u001b[0m rnn_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(rnn_input, last_hidden)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m context \u001b[38;5;241m=\u001b[39m attn_weights\u001b[38;5;241m.\u001b[39mbmm(encoder_outputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# B x 1 x N\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Final output layer (next word prediction) using the RNN hidden state and context vector\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mAttn.forward\u001b[1;34m(self, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate energies for each encoder output\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_len):\n\u001b[1;32m---> 24\u001b[0m     attn_energies[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msoftmax(attn_energies)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mAttn.score\u001b[1;34m(self, hidden, encoder_output)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(encoder_output)\n\u001b[1;32m---> 37\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[43mhidden\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m energy\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50dc3630-583c-44ad-bba7-e82dd8b23b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9fb27fe-4ea8-4719-be59-ec6ec373ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ab64fb1-127d-4b1f-8b3b-6406f48f7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8df1993-b476-46ce-b0c8-29c0b01258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 50000\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0fffaa7-34fb-49b4-8e19-5312c7122999",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Begin!\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Get training data for this cycle\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     training_pair \u001b[38;5;241m=\u001b[39m variables_from_pair(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     target_variable \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\random.py:346\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1fa997c-84a4-4932-af9b-5477f641c9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b01bc1a9-bd6c-4cb1-a7cc-33f957cb5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd3966a8-d61d-4330-a01f-254565885415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d115f2ae-f8a4-4acb-99d9-481f560b06bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_randomly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mevaluate_randomly\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_randomly\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     output_words, decoder_attn \u001b[38;5;241m=\u001b[39m evaluate(pair[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m     output_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\random.py:346\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7eb4e1c4-266e-487d-9413-db0a76081a5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'je'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_words, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mje suis trop froid .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mmatshow(attentions\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(sentence, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m----> 2\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m input_variable\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Run through encoder\u001b[39;00m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mvariable_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariable_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[43mindexes_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[0;32m      8\u001b[0m     var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mLongTensor(indexes)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mindexes_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'je'"
     ]
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83f0f532-d3eb-41cf-b0f3-162b7c04452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0253c9d8-907f-49e5-aa7f-c3f7d189d437",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'elle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_and_show_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melle a cinq ans de moins que moi .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mevaluate_and_show_attention\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_and_show_attention\u001b[39m(input_sentence):\n\u001b[1;32m---> 20\u001b[0m     output_words, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput =\u001b[39m\u001b[38;5;124m'\u001b[39m, input_sentence)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words))\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(sentence, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m----> 2\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m input_variable\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Run through encoder\u001b[39;00m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mvariable_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariable_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[43mindexes_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[0;32m      8\u001b[0m     var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mLongTensor(indexes)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mindexes_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'elle'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"elle a cinq ans de moins que moi .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fda69b17-0ef7-407a-9652-0c0baf8265e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'elle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_and_show_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melle est trop petit .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mevaluate_and_show_attention\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_and_show_attention\u001b[39m(input_sentence):\n\u001b[1;32m---> 20\u001b[0m     output_words, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput =\u001b[39m\u001b[38;5;124m'\u001b[39m, input_sentence)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words))\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(sentence, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m----> 2\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m input_variable\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Run through encoder\u001b[39;00m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mvariable_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariable_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[43mindexes_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[0;32m      8\u001b[0m     var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mLongTensor(indexes)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mindexes_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'elle'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"elle est trop petit .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58db7f2d-30ba-42d8-bada-cd57f5ff979c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'je'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_and_show_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mje ne crains pas de mourir .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mevaluate_and_show_attention\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_and_show_attention\u001b[39m(input_sentence):\n\u001b[1;32m---> 20\u001b[0m     output_words, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput =\u001b[39m\u001b[38;5;124m'\u001b[39m, input_sentence)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words))\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(sentence, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m----> 2\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m input_variable\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Run through encoder\u001b[39;00m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mvariable_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariable_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[43mindexes_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[0;32m      8\u001b[0m     var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mLongTensor(indexes)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mindexes_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'je'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"je ne crains pas de mourir .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce36245f-0001-4046-8ac7-939b37a2bee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_and_show_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc est un jeune directeur plein de talent .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mevaluate_and_show_attention\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_and_show_attention\u001b[39m(input_sentence):\n\u001b[1;32m---> 20\u001b[0m     output_words, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput =\u001b[39m\u001b[38;5;124m'\u001b[39m, input_sentence)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output_words))\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence, max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(sentence, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH):\n\u001b[1;32m----> 2\u001b[0m     input_variable \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     input_length \u001b[38;5;241m=\u001b[39m input_variable\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Run through encoder\u001b[39;00m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mvariable_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariable_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m \u001b[43mindexes_from_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     indexes\u001b[38;5;241m.\u001b[39mappend(EOS_token)\n\u001b[0;32m      8\u001b[0m     var \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mLongTensor(indexes)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mindexes_from_sentence\u001b[1;34m(lang, sentence)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [lang\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexes_from_sentence\u001b[39m(lang, sentence):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272ed09-cae8-474f-b3ce-89141b44183e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
